<?xml version="1.0" encoding="UTF-8"?>
<!--
;;
;;  This softeware is Copyright (c) 2009 A.F. Haffmans 
;;
;;    This file is part of cl-bliky.
;;
;;    cl-bliky is free software: you can redistribute it and/or modify
;;    it under the terms of the GNU General Public License as published by
;;   the Free Software Foundation, either version 3 of the License, or
;;    (at your option) any later version.
;;
;;    cl-bliky is distributed in the hope that it will be useful,
;;    but WITHOUT ANY WARRANTY; without even the implied warranty of
;;    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
;;    GNU General Public License for more details.
;;
;;    You should have received a copy of the GNU General Public License
;;    along with cl-bliky.  If not, see <http://www.gnu.org/licenses/>.
;;
;;

-->

<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/rss2full.xsl"?>
<?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<!-- rss version='2.0' xmlns:atom="http://www.w3.org/2005/Atom" -->
  <channel>
    <title> Programmer Notes </title>
    <link>  http://fons.github.com/ </link>
    <description> This is mostly concerned with programming. </description>
    <pubDate> Sat, 07 Nov 2009 18:42:03 EST </pubDate>
    
    <item>
      <title> Fourth NYSA Machine Learning Seminar </title>
      <link> http://fons.github.com/fourth-nysa-machine-learning-seminar.html </link>
      <description> &lt;p&gt;Friday I attended the 4&lt;sup&gt; th&lt;/sup&gt;  Machine Learning Symposium organized by the New York Academy of Sciences &lt;a href="http://www.nyas.org/"&gt;(NYSA)&lt;/a&gt;.  &lt;br /&gt; &lt;br /&gt;  The &lt;a href="http://www.nyas.org/events/Detail.aspx?cid=533f8dfe-d778-4c52-ba1b-3241bc9c8ca2"&gt;Symposium program&lt;/a&gt; consisted of four main talks given by local experts in the area of machine learning, interspersed with four graduate student talks, a poster session and a terrific lunch. &lt;br /&gt; &lt;br /&gt;  Since I'm not really hindered by any overwhelming expertise in this area I'll confine my self to a few breezy impressions of the main talks.  &lt;br /&gt; &lt;br /&gt;  The first one was given by Bob Bell, from AT&amp;T Bell Labs and a member of the team which won the &lt;a href="http://www.netflixprize.com/"&gt;Netflix prize.&lt;/a&gt; &lt;br /&gt; &lt;br /&gt;  &lt;/p&gt;&lt;p&gt;What made the contest challenging was not only the huge size of the data set  but also the fact that 99 % of the data was missing. In addition there were significant differences between training and test data. Regardless of whether a 10 % improvement of a movie rating system should be worthy of a million dollar prize, it provided a great way to test classifiers against real world data.&lt;br /&gt; &lt;br /&gt;  One thing that stood out for me  was that a relative small amount of users was responsible for 'most' of the ratings. He mentioned that they identified one user responsible for 5400 ratings on one particular day. This &lt;em&gt;could&lt;/em&gt; an data error on the Netflix side, where the time stamp was somehow misapplied. On the other hand it sounds like someone was trying to deliberately affect a large swath of ratings.  &lt;br /&gt; &lt;br /&gt;  The final classifier incorporated breakthroughs made by different teams in the earlier stages of this multi-year competition.One such breakthrough was to consider the previous genres of the movies someone has rated to determine future recommendations. That must seem rather obvious in retrospect. The other was a clever way called &lt;a href="http://portal.acm.org/citation.cfm?id=1557072"&gt;Collaborative Filtering&lt;/a&gt; which takes into account the time-dependency of people's movie preferences. &lt;br /&gt; &lt;br /&gt;  An ensemble of previously validated classifiers was used to construct the final classifier and the calculation to get the final result submitted to Netflix took almost a month, primarily because a power failure forced a restart of the calculation engine. In fact the use of an ensemble of classifiers of mentioned as one of the main lessons learned from the contest. The other was the power matrix factorization (i.e. treating users and preferences as independent parameters and using matrix to link the two) as a computational tool. &lt;/p&gt; </description> 
      <content:encoded><![CDATA[<p>Friday I attended the 4<sup> th</sup>  Machine Learning Symposium organized by the New York Academy of Sciences <a href="http://www.nyas.org/">(NYSA)</a>.  <br /> <br />  The <a href="http://www.nyas.org/events/Detail.aspx?cid=533f8dfe-d778-4c52-ba1b-3241bc9c8ca2">Symposium program</a> consisted of four main talks given by local experts in the area of machine learning, interspersed with four graduate student talks, a poster session and a terrific lunch. <br /> <br />  Since I'm not really hindered by any overwhelming expertise in this area I'll confine my self to a few breezy impressions of the main talks.  <br /> <br />  The first one was given by Bob Bell, from AT&amp;T Bell Labs and a member of the team which won the <a href="http://www.netflixprize.com/">Netflix prize.</a> <br /> <br />  </p><p>What made the contest challenging was not only the huge size of the data set  but also the fact that 99 % of the data was missing. In addition there were significant differences between training and test data. Regardless of whether a 10 % improvement of a movie rating system should be worthy of a million dollar prize, it provided a great way to test classifiers against real world data.<br /> <br />  One thing that stood out for me  was that a relative small amount of users was responsible for 'most' of the ratings. He mentioned that they identified one user responsible for 5400 ratings on one particular day. This <em>could</em> an data error on the Netflix side, where the time stamp was somehow misapplied. On the other hand it sounds like someone was trying to deliberately affect a large swath of ratings.  <br /> <br />  The final classifier incorporated breakthroughs made by different teams in the earlier stages of this multi-year competition.One such breakthrough was to consider the previous genres of the movies someone has rated to determine future recommendations. That must seem rather obvious in retrospect. The other was a clever way called <a href="http://portal.acm.org/citation.cfm?id=1557072">Collaborative Filtering</a> which takes into account the time-dependency of people's movie preferences. <br /> <br />  An ensemble of previously validated classifiers was used to construct the final classifier and the calculation to get the final result submitted to Netflix took almost a month, primarily because a power failure forced a restart of the calculation engine. In fact the use of an ensemble of classifiers of mentioned as one of the main lessons learned from the contest. The other was the power matrix factorization (i.e. treating users and preferences as independent parameters and using matrix to link the two) as a computational tool. </p> ]]></content:encoded>
      <guid> http://fons.github.com/fourth-nysa-machine-learning-seminar.html </guid>      
      <pubDate> Sat, 07 Nov 2009 09:49:51 EST </pubDate>
    </item>
    
    <item>
      <title> Embedding Equations in a Blog Post </title>
      <link> http://fons.github.com/embedding-equations-in-a-blog-post.html </link>
      <description> &lt;p&gt;I'm using a &lt;a href="http://github.com/fons/cl-bliky"&gt;home-grown blogging engine&lt;/a&gt; which converts pages formatted in &lt;a href="http://daringfireball.net/projects/markdown/"&gt;markdown&lt;/a&gt; to static html pages served from my &lt;a href="http://github.com/fons/fons.github.com"&gt;github account.&lt;/a&gt; If I want to include mathematical equations in my blog post my options are to use inline html code or to use one of the online &lt;a href="http://www.latex-project.org/"&gt;Latex&lt;/a&gt; &lt;a href="http://www.google.com/search?q=online+latex+equation+editor"&gt;equation editors.&lt;/a&gt; &lt;br&gt; &lt;br&gt; My requirements are simple: I want to be able to use the usual cast of mathematical symbols inlined in my main text as well format large equation blocks.  In this post I'll compare and contrast inline html with online editors provided by &lt;a href="http://www.sitmo.com/latex/"&gt;SITMO&lt;/a&gt;, &lt;a href="http://www.codecogs.com/components/equationeditor/equationeditor.php"&gt;CodeCogs&lt;/a&gt; and &lt;a href="http://www.texify.com/"&gt;Textify&lt;/a&gt;. &lt;br&gt; &lt;br&gt; To save you the trouble of having to wade through miles of text, I'll start of with my &lt;/p&gt;&lt;h2&gt;Conclusions&lt;/h2&gt;&lt;p&gt;Use HTML for inlining symbols and equations. Although those will never look as good in html as in Latex, the overall format of your text will suffer less.&lt;br&gt; &lt;br&gt; For equation blocks you have the choice between two online editors : &lt;a href="http://www.sitmo.com/latex/"&gt;SITMO&lt;/a&gt;, &lt;a href="http://www.codecogs.com/components/equationeditor/equationeditor.php"&gt;CodeCogs&lt;/a&gt;. When it comes to embedding latex code into your html both editors are comparable. When you're looking for more variety with regard to fonts or markup languages CodeCogs is your only alternative.&lt;br&gt; &lt;br&gt; If you want to use the url link to embed a large code block you probably would want to use a url shortner. &lt;a href=""http://tiny.url""&gt;Tiny url&lt;/a&gt; is a good option here.As an alternative both editors can generate a png image for you to embed.&lt;br&gt; &lt;br&gt;&lt;a href=""http://www.texify.com/links.php""&gt;Textify&lt;/a&gt; has a nice clean interface, but I can't embed the links it generates. My only alternative would appear to be to run my own instance of this service which is obviously not something I need or want to do. Furthermore, although it cleverly provides a shortened url, it uses &lt;a href=""http://bit.ly""&gt;bit.ly&lt;/a&gt; which unfortunately doesn't handle complex latex url's well.. &lt;br&gt; &lt;br&gt; Read on to find out how I reached these conclusions . &lt;/p&gt; </description> 
      <content:encoded><![CDATA[<p>I'm using a <a href="http://github.com/fons/cl-bliky">home-grown blogging engine</a> which converts pages formatted in <a href="http://daringfireball.net/projects/markdown/">markdown</a> to static html pages served from my <a href="http://github.com/fons/fons.github.com">github account.</a> If I want to include mathematical equations in my blog post my options are to use inline html code or to use one of the online <a href="http://www.latex-project.org/">Latex</a> <a href="http://www.google.com/search?q=online+latex+equation+editor">equation editors.</a> <br> <br> My requirements are simple: I want to be able to use the usual cast of mathematical symbols inlined in my main text as well format large equation blocks.  In this post I'll compare and contrast inline html with online editors provided by <a href="http://www.sitmo.com/latex/">SITMO</a>, <a href="http://www.codecogs.com/components/equationeditor/equationeditor.php">CodeCogs</a> and <a href="http://www.texify.com/">Textify</a>. <br> <br> To save you the trouble of having to wade through miles of text, I'll start of with my </p><h2>Conclusions</h2><p>Use HTML for inlining symbols and equations. Although those will never look as good in html as in Latex, the overall format of your text will suffer less.<br> <br> For equation blocks you have the choice between two online editors : <a href="http://www.sitmo.com/latex/">SITMO</a>, <a href="http://www.codecogs.com/components/equationeditor/equationeditor.php">CodeCogs</a>. When it comes to embedding latex code into your html both editors are comparable. When you're looking for more variety with regard to fonts or markup languages CodeCogs is your only alternative.<br> <br> If you want to use the url link to embed a large code block you probably would want to use a url shortner. <a href=""http://tiny.url"">Tiny url</a> is a good option here.As an alternative both editors can generate a png image for you to embed.<br> <br><a href=""http://www.texify.com/links.php"">Textify</a> has a nice clean interface, but I can't embed the links it generates. My only alternative would appear to be to run my own instance of this service which is obviously not something I need or want to do. Furthermore, although it cleverly provides a shortened url, it uses <a href=""http://bit.ly"">bit.ly</a> which unfortunately doesn't handle complex latex url's well.. <br> <br> Read on to find out how I reached these conclusions . </p> ]]></content:encoded>
      <guid> http://fons.github.com/embedding-equations-in-a-blog-post.html </guid>      
      <pubDate> Fri, 06 Nov 2009 06:32:19 EST </pubDate>
    </item>
    
    <item>
      <title> Toy Problem: Simple One Dimensional Least Squares Learner. </title>
      <link> http://fons.github.com/toy-problem-simple-one-dimensional-least-squares-learner.html </link>
      <description> &lt;p&gt;In chapter two of Hastie, Tibshirani and Friedman 's  &lt;a href="http://www-stat.stanford.edu/~tibs/ElemStatLearn/"&gt;'The Elements of Statistical Learning'&lt;/a&gt;  the authors discuss the use of least- squares regression to construct a data classifier for linearly separable data. &lt;br /&gt; &lt;br /&gt;  A set of training data together with the least-squares method is used to construct a hyper-plane in the data space. The classification of a data point depends on what side of the hyper-plane you end up on.&lt;br /&gt; &lt;br /&gt;  The example in Hastie uses two data classes in a two dimensional parameter space. I didn't grok the the example immediately, and I thought it would be helpful to try to construct my own much simpler example by staying in one dimension and using a simple normal distribution. The rest of this post describes the details. &lt;/p&gt; </description> 
      <content:encoded><![CDATA[<p>In chapter two of Hastie, Tibshirani and Friedman 's  <a href="http://www-stat.stanford.edu/~tibs/ElemStatLearn/">'The Elements of Statistical Learning'</a>  the authors discuss the use of least- squares regression to construct a data classifier for linearly separable data. <br /> <br />  A set of training data together with the least-squares method is used to construct a hyper-plane in the data space. The classification of a data point depends on what side of the hyper-plane you end up on.<br /> <br />  The example in Hastie uses two data classes in a two dimensional parameter space. I didn't grok the the example immediately, and I thought it would be helpful to try to construct my own much simpler example by staying in one dimension and using a simple normal distribution. The rest of this post describes the details. </p> ]]></content:encoded>
      <guid> http://fons.github.com/toy-problem-simple-one-dimensional-least-squares-learner.html </guid>      
      <pubDate> Sun, 01 Nov 2009 10:30:37 EST </pubDate>
    </item>
    
    <item>
      <title> Processing the Sieve in Python </title>
      <link> http://fons.github.com/processing-the-sieve-in-python.html </link>
      <description> &lt;p&gt;In a &lt;a href="http://www.prognotes.com/threading-the-sieve-in-python.html"&gt;previous post&lt;/a&gt; I discussed four methods to multi-thread the &lt;a href="http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes"&gt;Sieve of Erasthones&lt;/a&gt; in Python. I concluded that multi-threading didn't increase performance, and in fact could have a significant adverse effect. The &lt;a href="www.dabeaz.com/python/GIL.pdf"&gt;global interpretor lock (GIL)&lt;/a&gt; prevents threads from running concurrently and thus limits the upside of threading. The use of locks or avoiding the use of shared data can than decrease performance quite a bit. &lt;br /&gt; &lt;br /&gt;  In this section I'll be using Python's &lt;a href="http://docs.python.org/library/multiprocessing.html"&gt;multiprocessing&lt;/a&gt; module to 'multi-thread' the &lt;em&gt;Sieve&lt;/em&gt;. &lt;br /&gt; &lt;br /&gt;  The multiprocessing module spawns a number of processes and distributes the calculation amongst them.There is no equivalent to the GIL so I should be able to see some gain in performance as the number of processes increases. On the other hand, spawning processes means that there is startup overhead which may offset any performance gain due to the distribution of its execution across multiple processes.  However, I should still be able to investigate how performance scales with the number of processes, and whether the &lt;a href="http://docs.python.org/library/multiprocessing.html"&gt;multiprocessing module&lt;/a&gt; is able to take advantage of multiple cores. In this post I'll discuss four approaches to distributing the &lt;em&gt;Sieve&lt;/em&gt; algorithm, basically following the approaches I discussed &lt;a href="http://www.prognotes.com/threading-the-sieve-in-python.html"&gt;earlier&lt;/a&gt; when using the multi-threading package.The various approaches differ in the way the load is balanced and whether the state of the sieve is shared.&lt;br /&gt; &lt;br /&gt;  The source for the code discussed here and in the  &lt;a href="http://www.prognotes.com/threading-the-sieve-in-python.html"&gt;previous post&lt;/a&gt; can be found in  &lt;em&gt;prime_share.py&lt;/em&gt; in the &lt;a href="git://github.com/fons/blog-code.git"&gt;blog-code package&lt;/a&gt; on github. &lt;/p&gt; </description> 
      <content:encoded><![CDATA[<p>In a <a href="http://www.prognotes.com/threading-the-sieve-in-python.html">previous post</a> I discussed four methods to multi-thread the <a href="http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes">Sieve of Erasthones</a> in Python. I concluded that multi-threading didn't increase performance, and in fact could have a significant adverse effect. The <a href="www.dabeaz.com/python/GIL.pdf">global interpretor lock (GIL)</a> prevents threads from running concurrently and thus limits the upside of threading. The use of locks or avoiding the use of shared data can than decrease performance quite a bit. <br /> <br />  In this section I'll be using Python's <a href="http://docs.python.org/library/multiprocessing.html">multiprocessing</a> module to 'multi-thread' the <em>Sieve</em>. <br /> <br />  The multiprocessing module spawns a number of processes and distributes the calculation amongst them.There is no equivalent to the GIL so I should be able to see some gain in performance as the number of processes increases. On the other hand, spawning processes means that there is startup overhead which may offset any performance gain due to the distribution of its execution across multiple processes.  However, I should still be able to investigate how performance scales with the number of processes, and whether the <a href="http://docs.python.org/library/multiprocessing.html">multiprocessing module</a> is able to take advantage of multiple cores. In this post I'll discuss four approaches to distributing the <em>Sieve</em> algorithm, basically following the approaches I discussed <a href="http://www.prognotes.com/threading-the-sieve-in-python.html">earlier</a> when using the multi-threading package.The various approaches differ in the way the load is balanced and whether the state of the sieve is shared.<br /> <br />  The source for the code discussed here and in the  <a href="http://www.prognotes.com/threading-the-sieve-in-python.html">previous post</a> can be found in  <em>prime_share.py</em> in the <a href="git://github.com/fons/blog-code.git">blog-code package</a> on github. </p> ]]></content:encoded>
      <guid> http://fons.github.com/processing-the-sieve-in-python.html </guid>      
      <pubDate> Sun, 27 Sep 2009 14:52:50 EST </pubDate>
    </item>
    
    <item>
      <title> Threading the Sieve in Python </title>
      <link> http://fons.github.com/threading-the-sieve-in-python.html </link>
      <description> &lt;p&gt;This is the first of two posts on threading and multiprocessing in Python. In this post I'll explore the thread module and in the second post I'll look at Python's multiprocessing module. My starting point is the multi-threaded implementation of the &lt;a href="http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes"&gt;Sieve of Erasthones&lt;/a&gt; found in this &lt;a href="http://heather.cs.ucdavis.edu/~matloff/Python/PyThreads.pdf"&gt;tutorial on multi-threading in Python (pdf).&lt;/a&gt; &lt;br /&gt; &lt;br /&gt; Threading a compute-bound algorithm, like the &lt;em&gt;Sieve&lt;/em&gt; consists of subdividing of the main task into autonomous sub-tasks which share as little state as possible. Having no shared state eliminates the overhead that inevitably comes with locking. It turns out that Python is not very good at multi-threading compute-bound processes. &lt;a href="http://www.dabeaz.com/blog/dablog.html"&gt;This &lt;/a&gt;  &lt;a href="http://ttimo.vox.com/library/post/python-gil-threading-and-multicore-hardware.html"&gt;is &lt;/a&gt;&lt;a href="http://www.grouplens.org/node/244"&gt;not a &lt;/a&gt; &lt;a href="http://blog.ianbicking.org/gil-of-doom.html"&gt;surprise.&lt;/a&gt;  CPython has a global interpretor lock &lt;a href="http://www.dabeaz.com/python/GIL.pdf"&gt;(GIL)&lt;/a&gt; which prevents threads from running concurrently. &lt;br /&gt; &lt;br /&gt;  Regardless, there are other lessons I learned when multi-threading the &lt;em&gt;Sieve&lt;/em&gt; algorithm. One is that sharing state between threads may be unavoidable to achieve reasonable performance. In fact, if you &lt;em&gt;don't&lt;/em&gt; share state, performance can become predictable &lt;em&gt;worse&lt;/em&gt; as the number of threads of execution increases. &lt;br /&gt; &lt;br /&gt; The other is that locking can have a surprising impact on performance. It's not just the cost of locking per se, but the effect locking has on the distribution of work between the various threads. &lt;/p&gt; </description> 
      <content:encoded><![CDATA[<p>This is the first of two posts on threading and multiprocessing in Python. In this post I'll explore the thread module and in the second post I'll look at Python's multiprocessing module. My starting point is the multi-threaded implementation of the <a href="http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes">Sieve of Erasthones</a> found in this <a href="http://heather.cs.ucdavis.edu/~matloff/Python/PyThreads.pdf">tutorial on multi-threading in Python (pdf).</a> <br /> <br /> Threading a compute-bound algorithm, like the <em>Sieve</em> consists of subdividing of the main task into autonomous sub-tasks which share as little state as possible. Having no shared state eliminates the overhead that inevitably comes with locking. It turns out that Python is not very good at multi-threading compute-bound processes. <a href="http://www.dabeaz.com/blog/dablog.html">This </a>  <a href="http://ttimo.vox.com/library/post/python-gil-threading-and-multicore-hardware.html">is </a><a href="http://www.grouplens.org/node/244">not a </a> <a href="http://blog.ianbicking.org/gil-of-doom.html">surprise.</a>  CPython has a global interpretor lock <a href="http://www.dabeaz.com/python/GIL.pdf">(GIL)</a> which prevents threads from running concurrently. <br /> <br />  Regardless, there are other lessons I learned when multi-threading the <em>Sieve</em> algorithm. One is that sharing state between threads may be unavoidable to achieve reasonable performance. In fact, if you <em>don't</em> share state, performance can become predictable <em>worse</em> as the number of threads of execution increases. <br /> <br /> The other is that locking can have a surprising impact on performance. It's not just the cost of locking per se, but the effect locking has on the distribution of work between the various threads. </p> ]]></content:encoded>
      <guid> http://fons.github.com/threading-the-sieve-in-python.html </guid>      
      <pubDate> Sat, 12 Sep 2009 17:03:23 EST </pubDate>
    </item>
    
    <item>
      <title> Simplified command line processing with dyn-options.py </title>
      <link> http://fons.github.com/simplified-command-line-processing-with-dyn-optionspy.html </link>
      <description> &lt;p&gt;Am I the only one in the world who feels that using python's  &lt;em&gt;getopt&lt;/em&gt; is a bit of a struggle ? It involves a lot of boiler plate. Tedious refactoring is required each time you add or change an option.  This is not specific to Python, as most languages have a similar facility to parse the command line, which is similarly annoying. &lt;br /&gt; &lt;br /&gt;  I decided to create an easier way to process command line options, by transforming the command line into an immutable (read-only) object. The result is &lt;a href="http://github.com/fons/dyn_options/tree/master"&gt;dyn_options&lt;/a&gt;. &lt;br /&gt; &lt;br /&gt;  &lt;a href="http://github.com/fons/dyn_options/tree/master"&gt;dyn_options&lt;/a&gt; considers every string on the command line which starts with either  - or -- (i.e. a single or double dash) an option flag. The value of the option flag is a concatenation of everything that follows it, until the next flag is encountered.  A simple option flag is one without explicit values and is considered a boolean flag, set to &lt;em&gt;True&lt;/em&gt;. &lt;a href="http://github.com/fons/dyn_options/tree/master"&gt;dyn_options&lt;/a&gt; creates a read-only object, with attributes and values set to the command line option flags and values respectively. &lt;br /&gt; &lt;br /&gt;  So, '--opt4 hello world' will be converted to an option flag  called &lt;em&gt;opt4&lt;/em&gt;, with a value of &lt;em&gt;hello world&lt;/em&gt;. This makes dealing with spaces on the command line a lot easier. &lt;/p&gt; </description> 
      <content:encoded><![CDATA[<p>Am I the only one in the world who feels that using python's  <em>getopt</em> is a bit of a struggle ? It involves a lot of boiler plate. Tedious refactoring is required each time you add or change an option.  This is not specific to Python, as most languages have a similar facility to parse the command line, which is similarly annoying. <br /> <br />  I decided to create an easier way to process command line options, by transforming the command line into an immutable (read-only) object. The result is <a href="http://github.com/fons/dyn_options/tree/master">dyn_options</a>. <br /> <br />  <a href="http://github.com/fons/dyn_options/tree/master">dyn_options</a> considers every string on the command line which starts with either  - or -- (i.e. a single or double dash) an option flag. The value of the option flag is a concatenation of everything that follows it, until the next flag is encountered.  A simple option flag is one without explicit values and is considered a boolean flag, set to <em>True</em>. <a href="http://github.com/fons/dyn_options/tree/master">dyn_options</a> creates a read-only object, with attributes and values set to the command line option flags and values respectively. <br /> <br />  So, '--opt4 hello world' will be converted to an option flag  called <em>opt4</em>, with a value of <em>hello world</em>. This makes dealing with spaces on the command line a lot easier. </p> ]]></content:encoded>
      <guid> http://fons.github.com/simplified-command-line-processing-with-dyn-optionspy.html </guid>      
      <pubDate> Sat, 29 Aug 2009 19:15:49 EST </pubDate>
    </item>
    
    <item>
      <title> Factorials, Tail Recursion and CPS ... in C  </title>
      <link> http://fons.github.com/factorials-tail-recursion-and-cps--in-c-.html </link>
      <description> &lt;p&gt;Recursive algorithms are elegant. However, if the recursion is not a  &lt;a href="http://repository.readscheme.org/ftp/papers/ai-lab-pubs/AIM-453.pdf"&gt;tail call&lt;/a&gt;  the growth of the stack leads to a stack overflow. &lt;/p&gt;&lt;p&gt;Tail call recursion is a technique whereby the last call in a recursive function does not depend on the variables pushed on the stack. In other words the function returns the value of its additional (recursive) call. &lt;/p&gt;&lt;p&gt;Functional languages like Haskell or Lisp are designed to support the use of tail recursive algorithms.The JVM -although now the target platform of a lisp like &lt;a href="http://www.clojure.org"&gt;clojure&lt;/a&gt; or a hybrid functional language like &lt;a href="http://www.scala-lang.org"&gt;scala&lt;/a&gt; - &lt;a href="http://blogs.sun.com/jrose/entry/tail_calls_in_the_vm"&gt;does not support tail recursion at all&lt;/a&gt;. In C/C++ the compiler can in fact replace tail recursive calls with a simple loop, thereby eliminating the allocation for additional stack frames all together. In this post I'll consider various implementations of the humble factorial to illustrate some of these things. &lt;/p&gt; </description> 
      <content:encoded><![CDATA[<p>Recursive algorithms are elegant. However, if the recursion is not a  <a href="http://repository.readscheme.org/ftp/papers/ai-lab-pubs/AIM-453.pdf">tail call</a>  the growth of the stack leads to a stack overflow. </p><p>Tail call recursion is a technique whereby the last call in a recursive function does not depend on the variables pushed on the stack. In other words the function returns the value of its additional (recursive) call. </p><p>Functional languages like Haskell or Lisp are designed to support the use of tail recursive algorithms.The JVM -although now the target platform of a lisp like <a href="http://www.clojure.org">clojure</a> or a hybrid functional language like <a href="http://www.scala-lang.org">scala</a> - <a href="http://blogs.sun.com/jrose/entry/tail_calls_in_the_vm">does not support tail recursion at all</a>. In C/C++ the compiler can in fact replace tail recursive calls with a simple loop, thereby eliminating the allocation for additional stack frames all together. In this post I'll consider various implementations of the humble factorial to illustrate some of these things. </p> ]]></content:encoded>
      <guid> http://fons.github.com/factorials-tail-recursion-and-cps--in-c-.html </guid>      
      <pubDate> Sun, 09 Aug 2009 10:27:45 EST </pubDate>
    </item>
    
    <item>
      <title> CL-BLIKY : A simple lisp based blog engine </title>
      <link> http://fons.github.com/cl-bliky--a-simple-lisp-based-blog-engine.html </link>
      <description> &lt;p&gt;I 'm writing this using a self rolled blog engine called cl-bliky. I'm indebted to an excellent &lt;a href="http://roeim.net/vetle/docs/cl-webapp-intro/"&gt;tutorial&lt;/a&gt; put together by &lt;a href="http://roeim.net/vetle/"&gt;Vetle Roeim&lt;/a&gt;. His goal was obviously to put together a compelling tutorial and he succeeded. My goal was to use lisp in a small programming project, and developing a simple and easily customizable blog engine seemed like a good start. &lt;/p&gt; </description> 
      <content:encoded><![CDATA[<p>I 'm writing this using a self rolled blog engine called cl-bliky. I'm indebted to an excellent <a href="http://roeim.net/vetle/docs/cl-webapp-intro/">tutorial</a> put together by <a href="http://roeim.net/vetle/">Vetle Roeim</a>. His goal was obviously to put together a compelling tutorial and he succeeded. My goal was to use lisp in a small programming project, and developing a simple and easily customizable blog engine seemed like a good start. </p> ]]></content:encoded>
      <guid> http://fons.github.com/cl-bliky--a-simple-lisp-based-blog-engine.html </guid>      
      <pubDate> Sun, 19 Jul 2009 11:49:05 EST </pubDate>
    </item>
    
  </channel>
</rss>

